//
//  ClipGapBenchmarkTests.swift
//  VoiceLogin
//
//  Generated by GPT-5 (OpenAI) build: 2025-10-13
//  collaborator: robert
//  date: 10-13-2025
//

import XCTest
#if canImport(AVFoundation) && os(macOS)
@preconcurrency import AVFoundation
import QuartzCore

final class ClipGapBenchmarkTests: XCTestCase {

    // Set this to true to also play an audible tone you can listen for.
    private let audible = true

    // Helper for consistent short formatting (4 decimals)
    private func format4(_ x: Double) -> String {
        String(format: "%.4f", x)
    }

    @MainActor
    func testSpeakToClipGapBenchmark() async throws {
        let env = ProcessInfo.processInfo.environment
        let benchAudio = env["VK_BENCH_AUDIO"] == "1"
        let benchForce = env["VK_BENCH_FORCE"] == "1"
        guard benchAudio && benchForce else {
            throw XCTSkip("Local-only benchmark. To run: VK_BENCH_AUDIO=1 VK_BENCH_FORCE=1 (VK_BENCH_NO_TTS=1 to skip TTS).")
        }
        print("[ClipGapBenchmark] begin")
        let noTTS = env["VK_BENCH_NO_TTS"] == "1"
        if noTTS { print("[ClipGapBenchmark] VK_BENCH_NO_TTS=1 (skipping AVSpeechSynthesizer)") }

        // Prepare tone buffer (short sine wave) â€” louder and a bit longer for audibility
        let sampleRate: Double = 44_100
        let duration: Double = 0.35
        let freq: Double = 300
        let format = AVAudioFormat(standardFormatWithSampleRate: sampleRate, channels: 1)!
        let frameCount = AVAudioFrameCount(duration * sampleRate)
        guard let buffer = AVAudioPCMBuffer(pcmFormat: format, frameCapacity: frameCount) else {
            XCTFail("Failed to create buffer"); return
        }
        buffer.frameLength = frameCount
        if let ptr = buffer.floatChannelData?.pointee {
            for n in 0..<Int(frameCount) {
                let t = Double(n) / sampleRate
                let attack = min(1.0, t / 0.002)
                let release = min(1.0, (duration - t) / 0.02)
                let env = attack * release
                // Very loud tone for audibility (enveloped to avoid clicks)
                ptr[n] = audible ? Float(sin(2 * .pi * freq * t) * 0.9 * env) : 0.0
            }
        }

        // Helper: speak and await finish (with timeout)
        @MainActor
        func speak(_ text: String) async {
            var strongSynth: AVSpeechSynthesizer?
            var strongDelegate: NSObject?
            var resumed = false

            await withCheckedContinuation { (cont: CheckedContinuation<Void, Never>) in
                final class Delegate: NSObject, AVSpeechSynthesizerDelegate {
                    let onFinish: @Sendable () -> Void
                    init(onFinish: @escaping @Sendable () -> Void) { self.onFinish = onFinish }
                    func speechSynthesizer(_ s: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
                        onFinish()
                    }
                }

                let synth = AVSpeechSynthesizer()
                let del = Delegate {
                    // Hop to main actor before touching state/continuation.
                    Task { @MainActor in
                        if !resumed {
                            resumed = true
                            cont.resume()
                        }
                    }
                }

                synth.delegate = del
                let utt = AVSpeechUtterance(string: text)
                utt.voice = AVSpeechSynthesisVoice(language: "en-US")
                strongSynth = synth
                strongDelegate = del
                synth.speak(utt)

                // Safety timeout so the test never hangs.
                Task { @MainActor in
                    try? await Task.sleep(nanoseconds: 5_000_000_000) // 5s
                    if !resumed {
                        resumed = true
                        synth.stopSpeaking(at: .immediate)
                        cont.resume()
                    }
                }
            }
            _ = strongSynth; _ = strongDelegate
        }

        // Detect first audible sample using a tap on the source node; returns time from play() to audible.
        // Tapping the player node avoids mixer render-thread assertions on some macOS builds.
        func awaitAudibleStart(node: AVAudioNode, threshold: Float = 1e-4, t0: CFTimeInterval) async -> TimeInterval {
            await withCheckedContinuation { (cont: CheckedContinuation<TimeInterval, Never>) in
                // Keep state/mutations on main actor
                Task { @MainActor in
                    var resumed = false
                    node.installTap(onBus: 0, bufferSize: 2048, format: nil) { buf, _ in
                        // This closure may run on the audio render thread, not main.
                        guard let ch = buf.floatChannelData?.pointee else { return }
                        let count = Int(buf.frameLength)
                        var peak: Float = 0
                        // Quick peak detection
                        for i in 0..<count {
                            let v = abs(ch[i])
                            if v > peak { peak = v }
                        }
                        if peak > threshold {
                            // Hop to main to mutate state/remove tap/resume continuation
                            Task { @MainActor in
                                if !resumed {
                                    resumed = true
                                    let dt = CACurrentMediaTime() - t0
                                    cont.resume(returning: dt)
                                }
                            }
                        }
                    }
                }
            }
        }

        // Clip-only cold start time to audible
        func measureClipOnly() async -> TimeInterval {
            print("[ClipGapBenchmark] clipOnly: setup")
            let engine = AVAudioEngine()
            let player = AVAudioPlayerNode()
            engine.attach(player)
            engine.connect(player, to: engine.mainMixerNode, format: buffer.format)
            engine.mainMixerNode.outputVolume = 1.0
            player.volume = 1.0
            engine.prepare()
            print("[ClipGapBenchmark] clipOnly: engine.start()")
            try? engine.start()
            // Give the engine a tick to stabilize before play/tap
            try? await Task.sleep(nanoseconds: 2_000_000) // 2 ms
            // Use async scheduleBuffer without awaiting it; give it a tick to enqueue
            Task { await player.scheduleBuffer(buffer, at: nil, options: []) }
            try? await Task.sleep(nanoseconds: 1_000_000) // 1 ms
            let t0 = CACurrentMediaTime()
            print("[ClipGapBenchmark] clipOnly: play")
            let audibleTask = Task { await awaitAudibleStart(node: player, t0: t0) }
            player.play()
            let dt = await audibleTask.value
            player.stop(); engine.stop()
            print("[ClipGapBenchmark] clipOnly: dt=\(format4(dt))s")
            return dt
        }

        // Case A: one-shot (setup after speak finishes)
        func measureOneShot() async -> TimeInterval {
            print("[ClipGapBenchmark] oneShot: speak")
            if !noTTS { await speak("Hi.") }
            print("[ClipGapBenchmark] oneShot: setup")
            let engine = AVAudioEngine()
            let player = AVAudioPlayerNode()
            engine.attach(player)
            engine.connect(player, to: engine.mainMixerNode, format: buffer.format)
            engine.mainMixerNode.outputVolume = 1.0
            player.volume = 1.0
            engine.prepare()
            print("[ClipGapBenchmark] oneShot: engine.start()")
            try? engine.start()
            try? await Task.sleep(nanoseconds: 2_000_000)
            // Schedule asynchronously but do not await; yield briefly to enqueue
            Task { await player.scheduleBuffer(buffer, at: nil, options: []) }
            try? await Task.sleep(nanoseconds: 1_000_000)
            let t0 = CACurrentMediaTime()
            print("[ClipGapBenchmark] oneShot: play")
            let audibleTask = Task { await awaitAudibleStart(node: player, t0: t0) }
            player.play()
            let dt = await audibleTask.value
            player.stop(); engine.stop()
            print("[ClipGapBenchmark] oneShot: dt=\(format4(dt))s")
            return dt
        }

        // Case B: prepare + start (engine ready before speak finishes)
        func measurePrepared() async -> TimeInterval {
            print("[ClipGapBenchmark] prepared: setup")
            let engine = AVAudioEngine()
            let player = AVAudioPlayerNode()
            engine.attach(player)
            engine.connect(player, to: engine.mainMixerNode, format: buffer.format)
            engine.mainMixerNode.outputVolume = 1.0
            player.volume = 1.0
            engine.prepare()
            print("[ClipGapBenchmark] prepared: engine.start()")
            try? engine.start()
            try? await Task.sleep(nanoseconds: 2_000_000)
            // Pre-schedule before speaking so we can start instantly
            Task { await player.scheduleBuffer(buffer, at: nil, options: []) }
            try? await Task.sleep(nanoseconds: 1_000_000)
            print("[ClipGapBenchmark] prepared: speak")
            if !noTTS { await speak("Hi.") }
            let t0 = CACurrentMediaTime()
            print("[ClipGapBenchmark] prepared: play")
            let audibleTask = Task { await awaitAudibleStart(node: player, t0: t0) }
            player.play()
            let dt = await audibleTask.value
            player.stop(); engine.stop()
            print("[ClipGapBenchmark] prepared: dt=\(format4(dt))s")
            return dt
        }

        // TTS-only timing (utterance start -> finish)
        func measureTTSOnly() async -> TimeInterval {
            if noTTS { return 0 }
            let t0 = CACurrentMediaTime()
            await speak("Hi.")
            return CACurrentMediaTime() - t0
        }

        // Warm-up
        _ = await measureClipOnly()
        _ = await measureTTSOnly()
        _ = await measureOneShot()
        _ = await measurePrepared()

        // Trials
        var ttsOnly: [TimeInterval] = []
        var clipOnly: [TimeInterval] = []
        var oneShot: [TimeInterval] = []
        var prepared: [TimeInterval] = []
        print("[ClipGapBenchmark] trials: start")
        for _ in 0..<3 {
            clipOnly.append(await measureClipOnly())
            ttsOnly.append(await measureTTSOnly())
            oneShot.append(await measureOneShot())
            prepared.append(await measurePrepared())
        }

        func stats(_ xs: [TimeInterval]) -> (avg: Double, min: Double, max: Double) {
            let avg = xs.reduce(0, +) / Double(xs.count)
            return (avg, xs.min() ?? 0, xs.max() ?? 0)
        }
        let sA = stats(oneShot)
        let sB = stats(prepared)
        let sT = stats(ttsOnly)
        let sC = stats(clipOnly)

        print("[ClipGapBenchmark] tts-only    avg=\(format4(sT.avg))s min=\(format4(sT.min))s max=\(format4(sT.max))s")
        print("[ClipGapBenchmark] clip-only   avg=\(format4(sC.avg))s min=\(format4(sC.min))s max=\(format4(sC.max))s")
        print("[ClipGapBenchmark] one-shot    avg=\(format4(sA.avg))s min=\(format4(sA.min))s max=\(format4(sA.max))s")
        print("[ClipGapBenchmark] prepared    avg=\(format4(sB.avg))s min=\(format4(sB.min))s max=\(format4(sB.max))s")

        // No assertions by default; this is exploratory. If you want, uncomment:
        // XCTAssertLessThan(sB.avg, sA.avg * 0.8, "Prepared path should generally reduce gap")
    }
}
#endif
