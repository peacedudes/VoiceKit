//
//  VoiceQueueTests.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI) - collaborator: rdoggett
//  date: 09-16-2025
//

import XCTest
import VoiceKit

@MainActor
internal final class VoiceQueueTests: XCTestCase {

    // A tiny fake engine to validate sequencing without AV/Speech.
    @MainActor
    final class FakeIO: VoiceIO, TTSConfigurable {
        var onListeningChanged: ((Bool) -> Void)?
        var onTranscriptChanged: ((String) -> Void)?
        var onLevelChanged: ((CGFloat) -> Void)?
        var onTTSSpeakingChanged: ((Bool) -> Void)?
        var onTTSPulse: ((CGFloat) -> Void)?
        var onStatusMessageChanged: ((String?) -> Void)?

        var log: [String] = []
        var stopped = false

        func ensurePermissions() async throws {}
        func configureSessionIfNeeded() async throws {}

        func speak(_ text: String) async {
            log.append("speak:\(text)")
            try? await Task.sleep(nanoseconds: 40_000_000)
        }

        // TTSConfigurable
        func availableVoices() -> [TTSVoiceInfo] { [] }
        func setVoiceProfile(_ profile: TTSVoiceProfile) {}
        func getVoiceProfile(id: String) -> TTSVoiceProfile? { nil }
        func setDefaultVoiceProfile(_ profile: TTSVoiceProfile) {}
        func getDefaultVoiceProfile() -> TTSVoiceProfile? { nil }
        func setTuning(_ tuning: Tuning) {}
        func getTuning() -> Tuning { .init() }
        func speak(_ text: String, using voiceID: String?) async {
            log.append("speak:\(text):\(voiceID ?? "nil")")
            try? await Task.sleep(nanoseconds: 40_000_000)
        }
        func stopSpeakingNow() { log.append("stopSpeakingNow") }

        func prepareClip(url: URL, gainDB: Float) async throws { log.append("prepare:\(url.lastPathComponent):\(gainDB)") }
        func startPreparedClip() async throws { log.append("startPrepared") }
        func playClip(url: URL, gainDB: Float) async throws { log.append("play:\(url.lastPathComponent):\(gainDB)") }

        func listen(timeout: TimeInterval, inactivity: TimeInterval, record: Bool) async throws -> VoiceResult {
            return VoiceResult(transcript: "", recordingURL: nil)
        }

        func stopAll() { stopped = true; log.append("stopAll") }
        func hardReset() { log.append("hardReset") }
    }

    private func tempURL(_ name: String) -> URL {
        FileManager.default.temporaryDirectory.appendingPathComponent(name + ".caf")
    }

    func testSpeakThenSFXIsPreScheduledAndStarted() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)

        let url = tempURL("ding")
        queue.enqueue(.speak(text: "Hello", voiceID: "v1"))
        queue.enqueue(.sfx(url: url, gainDB: 6))

        await queue.play()
        // Expect prepare before speak, then startPrepared after speak
        XCTAssertEqual(io.log, [
            "prepare:ding.caf:6.0",
            "speak:Hello:v1",
            "startPrepared"
        ])
    }

    func testSFXWithoutPriorSpeakUsesPlayBoosted() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)
        let url = tempURL("pop")

        queue.enqueue(.sfx(url: url, gainDB: 3))
        await queue.play()

        XCTAssertEqual(io.log, ["play:pop.caf:3.0"])
    }

    func testPauseWaitsBetweenItems() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)
        let start = Date()
        queue.enqueue(.speak(text: "A", voiceID: nil))
        queue.enqueue(.pause(seconds: 0.08))
        queue.enqueue(.speak(text: "B", voiceID: nil))
        await queue.play()
        let elapsed = Date().timeIntervalSince(start)
        XCTAssertGreaterThanOrEqual(elapsed, 0.11)
    }

    func testMultiChannelRunsConcurrentlyWhenFactoryProvided() async {
        let io0 = FakeIO()
        let queue = VoiceQueue(primary: io0) {
            return FakeIO()
        }
        queue.enqueue(.speak(text: "ch0-1", voiceID: nil), on: 0)
        queue.enqueue(.speak(text: "ch0-2", voiceID: nil), on: 0)

        queue.enqueue(.speak(text: "ch1-1", voiceID: nil), on: 1)
        queue.enqueue(.speak(text: "ch1-2", voiceID: nil), on: 1)

        let startTime = Date()
        await queue.play()
        let elapsed = Date().timeIntervalSince(startTime)
        // Two channels of ~80ms total each should overlap, completing under ~0.18s
        // extra time for CI tests 
        XCTAssertLessThan(elapsed, 0.5)
    }

    func testCancelAllStopsFurtherProcessing() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)
        let url = tempURL("bell")

        queue.enqueue(.speak(text: "A", voiceID: nil))
        queue.enqueue(.sfx(url: url, gainDB: 4))
        queue.enqueue(.speak(text: "B", voiceID: nil))

        // Start playback and cancel quickly
        Task { await queue.play() }
        try? await Task.sleep(nanoseconds: 20_000_000)
        queue.cancelAll()

        // Allow tasks to unwind
        try? await Task.sleep(nanoseconds: 80_000_000)

        // We should see stopAll and not necessarily the full sequence
        XCTAssertTrue(io.log.contains("stopAll"))
    }

    func testEmbeddedSFXParsingQueuesParts() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)
        let ding = tempURL("ding")
        let resolver: VoiceQueue.SFXResolver = { name in
            if name == "ding" { return ding }
            return nil
        }

        queue.enqueueParsingSFX(text: "Hello [sfx:ding] world", resolver: resolver, defaultVoiceID: "vX")
        await queue.play()

        // Should be: prepare(ding) -> speak("Hello ") -> startPrepared -> speak(" world")
        XCTAssertEqual(io.log, [
            "prepare:ding.caf:0.0",
            "speak:Hello :vX",
            "startPrepared",
            "speak: world:vX"
        ])
    }

    func testEmbeddedSFXParsingHandlesSpacesAndOddChars() async {
        let io = FakeIO()
        let queue = VoiceQueue(primary: io)
        let fx = tempURL("fx")
        let resolver: VoiceQueue.SFXResolver = { name in
            // Name should preserve odd chars and leading spaces are trimmed by regex
            if name == "a/b:c.d-e" { return fx }
            return nil
        }

        queue.enqueueParsingSFX(text: "Hello [sfx:  a/b:c.d-e] world", resolver: resolver, defaultVoiceID: "vY")
        await queue.play()

        // Should be: prepare(fx) -> speak("Hello ") -> startPrepared -> speak(" world")
        XCTAssertEqual(io.log, [
            "prepare:fx.caf:0.0",
            "speak:Hello :vY",
            "startPrepared",
            "speak: world:vY"
        ])
    }
}
