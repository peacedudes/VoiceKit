//
//  VoicePublic.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI)
//  collaborator: robert
//  date: 09-16-2025
//

import Foundation
import CoreGraphics

// MARK: - Public results and errors

public struct VoiceResult: Sendable {
    public let transcript: String
    public let recordingURL: URL?
    public init(transcript: String, recordingURL: URL?) {
        self.transcript = transcript
        self.recordingURL = recordingURL
    }
}

public struct SimpleError: LocalizedError, Sendable {
    public var message: String
    public init(_ message: String) { self.message = message }
    public var errorDescription: String? { message }
}

// MARK: - VoiceIO API (main-actor)

@MainActor
public protocol VoiceIO: AnyObject {
    var onListeningChanged: ((Bool) -> Void)? { get set }
    var onTranscriptChanged: ((String) -> Void)? { get set }
    var onLevelChanged: ((CGFloat) -> Void)? { get set }
    var onTTSSpeakingChanged: ((Bool) -> Void)? { get set }
    var onTTSPulse: ((CGFloat) -> Void)? { get set }
    var onStatusMessageChanged: ((String?) -> Void)? { get set }

    func ensurePermissions() async throws
    func configureSessionIfNeeded() async throws

    func speak(_ text: String) async
    func listen(timeout: TimeInterval, inactivity: TimeInterval, record: Bool) async throws -> VoiceResult

    func prepareBoosted(url: URL, gainDB: Float) async throws
    func startPreparedBoosted() async throws
    func playBoosted(url: URL, gainDB: Float) async throws

    func stopAll()
    func hardReset()
}

@MainActor
public extension VoiceIO {
    func prepareBoosted(url: URL) async throws { try await prepareBoosted(url: url, gainDB: 0) }
    func playBoosted(url: URL) async throws { try await playBoosted(url: url, gainDB: 0) }
    func queueSFX(url: URL, gainDB: Float = 0) async throws { try await prepareBoosted(url: url, gainDB: gainDB) }

    func listen(timeout: TimeInterval,
                inactivity: TimeInterval,
                record: Bool,
                context: RecognitionContext = .init()) async throws -> VoiceResult {
        if let real = self as? RealVoiceIO {
            real.setRecognitionContext(context)
        }
        return try await listen(timeout: timeout, inactivity: inactivity, record: record)
    }
}

// MARK: - TTS models and configuration

public struct TTSVoiceInfo: Identifiable, Hashable, Codable, Sendable {
    public let id: String
    public let name: String
    public let language: String
    public init(id: String, name: String, language: String) {
        self.id = id; self.name = name; self.language = language
    }
}

public struct TTSVoiceProfile: Sendable, Equatable, Codable {
    public let id: String
    public var rate: Double
    public var pitch: Float
    public var volume: Float

    public init(id: String, rate: Double = 0.5, pitch: Float = 1.0, volume: Float = 1.0) {
        self.id = id
        self.rate = rate
        self.pitch = pitch
        self.volume = volume
    }
}

public struct TTSMasterControl: Sendable, Equatable, Codable {
    public var rateVariation: Float
    public var pitchVariation: Float
    public var volume: Float

    public init(rateVariation: Float = 0, pitchVariation: Float = 0, volume: Float = 1.0) {
        self.rateVariation = rateVariation
        self.pitchVariation = pitchVariation
        self.volume = volume
    }
}

/// Annotated @MainActor to match RealVoiceIOâ€™s isolation and allow calls through existential.
@MainActor
public protocol TTSConfigurable: AnyObject {
    func setVoiceProfile(_ profile: TTSVoiceProfile)
    func getVoiceProfile(id: String) -> TTSVoiceProfile?
    func setDefaultVoiceProfile(_ profile: TTSVoiceProfile)
    func getDefaultVoiceProfile() -> TTSVoiceProfile?
    func setMasterControl(_ master: TTSMasterControl)
    func getMasterControl() -> TTSMasterControl

    /// Speak text using an optional voice profile id (nil uses default).
    func speak(_ text: String, using voiceID: String?) async
}

// MARK: - Recognition context

public struct RecognitionContext: Sendable {
    public enum Expectation: Sendable {
        case freeform
        case name(allowed: [String])
        case number
    }
    public var expectation: Expectation
    public init(expectation: Expectation = .freeform) { self.expectation = expectation }
}

public extension RecognitionContext {
    static var numericContextualStrings: [String] {
        let digits = (0...20).map { String($0) } + ["30","40","50","60","70","80","90","100"]
        let words = ["zero","one","two","three","four","five","six","seven","eight","nine",
                     "ten","eleven","twelve","thirteen","fourteen","fifteen",
                     "sixteen","seventeen","eighteen","nineteen","twenty",
                     "thirty","forty","fifty","sixty","seventy","eighty","ninety","hundred"]
        return digits + words
    }
}

// MARK: - Operation gate

public actor VoiceOpGate {
    private var busy = false
    public init() {}
    public func acquire() async {
        while busy { try? await Task.sleep(nanoseconds: 200_000) }
        busy = true
    }
    public func release() async { busy = false }
    public func forceClear() async { busy = false }
}
