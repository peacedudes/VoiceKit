//
//  RealVoiceIO+TTS.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI)
//  collaborator: robert
//  date: 09-15-2025
//

import Foundation
import CoreGraphics
@preconcurrency import AVFoundation
import QuartzCore

@MainActor
extension RealVoiceIO: TTSConfigurable {

    // MARK: - TTSConfigurable

    public func availableVoices() -> [TTSVoiceInfo] {
        AVSpeechSynthesisVoice.speechVoices().map { TTSVoiceInfo(id: $0.identifier, name: $0.name, language: $0.language) }
    }

    public func setVoiceProfile(_ profile: TTSVoiceProfile) { profilesByID[profile.id] = profile }
    public func getVoiceProfile(id: String) -> TTSVoiceProfile? { profilesByID[id] }
    public func setDefaultVoiceProfile(_ profile: TTSVoiceProfile) { profilesByID[profile.id] = profile; defaultProfile = profile }
    public func getDefaultVoiceProfile() -> TTSVoiceProfile? { defaultProfile }
    public func setMasterControl(_ master: TTSMasterControl) { self.master = master }
    public func getMasterControl() -> TTSMasterControl { master }
    public func stopSpeakingNow() { synthesizer.stopSpeaking(at: .immediate) }

    // MARK: - VoiceIO speak

    public func speak(_ text: String) async { await speak(text, using: nil) }

    public func speak(_ text: String, using voiceID: String?) async {
        if Task.isCancelled { return }
        await opGate.acquire()
        defer { Task { await opGate.release() } }
        if Task.isCancelled { return }
        await stopRecognitionAsync()

        await withCheckedContinuation { (cont: CheckedContinuation<Void, Never>) in
            if Task.isCancelled { cont.resume(); return }
            let utt = AVSpeechUtterance(string: text)
            applyProfile(to: utt, voiceID: voiceID)
            let key = ObjectIdentifier(utt)
            speakContinuations[key] = cont
            synthesizer.speak(utt)
        }
    }

    func setRecognitionContext(_ ctx: RecognitionContext) { recognitionContext = ctx }
}

// MARK: - TTS helpers

@MainActor
extension RealVoiceIO {

    func applyProfile(to utt: AVSpeechUtterance, voiceID: String?) {
        let profile = (voiceID.flatMap { profilesByID[$0] }) ?? defaultProfile
        if let pid = profile?.id, let v = AVSpeechSynthesisVoice(identifier: pid) { utt.voice = v }
        else { utt.voice = AVSpeechSynthesisVoice(language: Locale.autoupdatingCurrent.identifier) }

        let sysMin = AVSpeechUtteranceMinimumSpeechRate
        let sysMax = AVSpeechUtteranceMaximumSpeechRate
        let span = sysMax - sysMin
        var rate = sysMin + span * (profile?.rate ?? 0.5)
        if master.rateVariation > 0 {
            let jitter = (Float.random(in: -master.rateVariation...master.rateVariation)) * Float(span)
            rate = max(sysMin, min(sysMax, rate + jitter))
        }
        utt.rate = rate

        var pitch = profile?.pitch ?? 1.0
        if master.pitchVariation > 0 {
            pitch += Float.random(in: -master.pitchVariation...master.pitchVariation)
        }
        utt.pitchMultiplier = max(0.5, min(2.0, pitch))

        let baseVol = profile?.volume ?? 1.0
        utt.volume = max(0.0, min(1.0, baseVol * master.volume))
    }

    func ttsStartPulse() {
        onTTSSpeakingChanged?(true)
        ttsPulseTask?.cancel()
        ttsPhase = 0
        ttsGlow = 0
        ttsPulseTask = Task { [weak self] in
            while let self, !Task.isCancelled {
                await MainActor.run {
                    self.ttsPhase += 0.14
                    if self.ttsPhase > .pi * 2 { self.ttsPhase -= .pi * 2 }
                    let base = (sin(self.ttsPhase) + 1) / 2
                    let baseAmp = 0.22 + 0.28 * base
                    self.ttsGlow *= 0.78
                    let level = min(1, max(0, baseAmp + self.ttsGlow))
                    self.onTTSPulse?(level)
                }
                try? await Task.sleep(nanoseconds: 33_333_333)
            }
        }
    }

    func ttsStopPulse() {
        ttsPulseTask?.cancel()
        ttsPulseTask = nil
        ttsGlow = 0
        onTTSPulse?(0.0)
        onTTSSpeakingChanged?(false)
    }

    fileprivate func ttsDidStart(key: ObjectIdentifier) { ttsStartPulse() }
    fileprivate func ttsWillSpeak(range: NSRange, text: String) { ttsGlow = min(1.0, ttsGlow + 0.55) }
    fileprivate func ttsDidFinishOrCancel(key: ObjectIdentifier) {
        speakContinuations.removeValue(forKey: key)?.resume()
        ttsSuppressUntil = CACurrentMediaTime() + config.ttsSuppressAfterFinish
        if autoStartPreparedAfterTTS, let player = boostPlayer, !player.isPlaying {
            autoStartPreparedAfterTTS = false
            player.play()
        }
        ttsStopPulse()
    }
}

// MARK: - AVSpeechSynthesizer delegate

final class SpeechDelegate: NSObject, AVSpeechSynthesizerDelegate {
    private unowned(unsafe) let owner: RealVoiceIO
    init(owner: RealVoiceIO) {
        self.owner = owner
        super.init()
    }
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in self.owner.ttsDidStart(key: key) }
    }
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, willSpeakRangeOfSpeechString characterRange: NSRange, utterance: AVSpeechUtterance) {
        let text = utterance.speechString
        Task { @MainActor in self.owner.ttsWillSpeak(range: characterRange, text: text) }
    }
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in self.owner.ttsDidFinishOrCancel(key: key) }
    }
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in self.owner.ttsDidFinishOrCancel(key: key) }
    }
}
