//
//  RealVoiceIO.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI)
//  collaborator: robert
//  date: 09-15-2025
//

import Foundation
import CoreGraphics
@preconcurrency import AVFoundation
@preconcurrency import Speech

@MainActor
public final class RealVoiceIO: NSObject, VoiceIO {

    // MARK: - Config

    public struct Config: Sendable {
        public var trimPrePad: Double = 0.02
        public var trimPostPad: Double = 0.50
        public var ttsSuppressAfterFinish: Double = 0.25
        public var boostedWaitTimeoutSeconds: Double = 3.0
        public init(trimPrePad: Double = 0.02, trimPostPad: Double = 0.50, ttsSuppressAfterFinish: Double = 0.25, boostedWaitTimeoutSeconds: Double = 3.0) {
            self.trimPrePad = trimPrePad
            self.trimPostPad = trimPostPad
            self.ttsSuppressAfterFinish = ttsSuppressAfterFinish
            self.boostedWaitTimeoutSeconds = boostedWaitTimeoutSeconds
        }
    }
    let config: Config

    // MARK: - Callbacks

    public var onListeningChanged: ((Bool) -> Void)?
    public var onTranscriptChanged: ((String) -> Void)?
    public var onLevelChanged: ((CGFloat) -> Void)?
    public var onTTSSpeakingChanged: ((Bool) -> Void)?
    public var onTTSPulse: ((CGFloat) -> Void)?
    public var onStatusMessageChanged: ((String?) -> Void)?

    // MARK: - TTS

    let synthesizer = AVSpeechSynthesizer()
    var speakContinuations: [ObjectIdentifier: CheckedContinuation<Void, Never>] = [:]
    lazy var speechDelegate: SpeechDelegate = SpeechDelegate(owner: self)
    var ttsPulseTask: Task<Void, Never>?
    var ttsPhase: CGFloat = 0
    var ttsGlow: CGFloat = 0
    var ttsSuppressUntil: CFTimeInterval = 0

    var profilesByID: [String: TTSVoiceProfile] = [:]
    var defaultProfile: TTSVoiceProfile?
    var master: TTSMasterControl = .init()

    // MARK: - STT

    let speechRecognizer = SFSpeechRecognizer(locale: .autoupdatingCurrent)
    var audioEngine: AVAudioEngine?
    var tapInstalled = false
    var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    var recognitionTask: SFSpeechRecognitionTask?
    var hasFinishedRecognition = false

    var recognitionContext: RecognitionContext = .init()
    var firstSpeechStart: Double?
    var lastSpeechEnd: Double?
    var latestTranscript: String = ""

    var listenCont: CheckedContinuation<VoiceResult, Error>?
    var listenOutURL: URL?
    var listenOutFile: AVAudioFile?
    var finishQueued: VoiceResult?

    var listenOverallTask: Task<Void, Never>?
    var listenInactivityTask: Task<Void, Never>?

    var wasInterrupted = false
    var wasPlayingBoost = false

    // MARK: - Boosted SFX

    var boostEngine: AVAudioEngine?
    var boostPlayer: AVAudioPlayerNode?
    var boostEQ: AVAudioUnitEQ?
    var autoStartPreparedAfterTTS = false
    let boostQueue = BoostQueue()
    var boostWaiters: [UUID: CheckedContinuation<Void, Never>] = [:]

    // MARK: - Op gate

    let opGate = VoiceOpGate()

    // MARK: - Lifecycle

    public init(config: Config = Config()) {
        self.config = config
        super.init()
        synthesizer.delegate = speechDelegate
        installInterruptionObservers()
    }

    deinit {
        #if os(iOS)
        NotificationCenter.default.removeObserver(self)
        #endif
    }

    // MARK: - Permissions / Session

    public func ensurePermissions() async throws {
        let micOK = await PermissionBridge.awaitMicPermission()
        guard micOK else { throw SimpleError("Microphone permission denied.") }

        let speechAuth = await PermissionBridge.awaitSpeechAuth()
        guard speechAuth == .authorized else { throw SimpleError("Speech permission denied.") }
        guard speechRecognizer?.isAvailable == true else { throw SimpleError("Speech recognizer unavailable.") }
    }

    public func configureSessionIfNeeded() async throws {
        #if os(iOS)
        let s = AVAudioSession.sharedInstance()
        try? s.setActive(false, options: [])
        var opts: AVAudioSession.CategoryOptions = [.defaultToSpeaker, .duckOthers]
        opts.insert(.allowBluetoothHFP)
        try s.setCategory(.playAndRecord, mode: .voiceChat, options: opts)
        try s.setPreferredSampleRate(44100)
        try s.setPreferredIOBufferDuration(0.01)
        try s.setActive(true, options: [])
        #endif
    }

    // MARK: - Public reset/stop

    public func stopAll() {
        synthesizer.stopSpeaking(at: .immediate)
        for (_, cont) in speakContinuations { cont.resume() }
        speakContinuations.removeAll()
        stopBoostedPlayback()
        stopRecognition()
        onListeningChanged?(false)
    }

    public func hardReset() {
        stopAll()
        hasFinishedRecognition = false
        firstSpeechStart = nil
        lastSpeechEnd = nil
        latestTranscript = ""
        autoStartPreparedAfterTTS = false
        onTranscriptChanged?("")
        onLevelChanged?(0)
        listenOverallTask?.cancel(); listenOverallTask = nil
        listenInactivityTask?.cancel(); listenInactivityTask = nil
        tapInstalled = false
        Task { await opGate.forceClear() }
    }
}
