//
//  RealVoiceIO+Trimming.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI)
//  collaborator: rdoggett
//  date: 09-15-2025
//

import Foundation
@preconcurrency import AVFoundation
import Accelerate

@MainActor
extension RealVoiceIO {

    func trimAudioSmart(inputURL: URL,
                        sttStart: Double?,
                        sttEnd: Double?,
                        prePad: Double,
                        postPad: Double) -> URL? {
        do {
            let inFile = try AVAudioFile(forReading: inputURL)
            let sampleRate = inFile.fileFormat.sampleRate
            let totalFrames = inFile.length
            let duration = Double(totalFrames) / sampleRate

            let fallback = (sttStart == nil || sttEnd == nil || sttEnd! <= sttStart!)
            var start = sttStart ?? 0
            var end = sttEnd ?? duration

            if fallback {
                let targetFormat = inFile.processingFormat
                let chunk: AVAudioFrameCount = 8192
                inFile.framePosition = 0
                let threshDB: Float = -45
                var foundStart: Double?
                var lastNonSilent: Double = 0

                while inFile.framePosition < totalFrames {
                    let remaining = AVAudioFrameCount(totalFrames - inFile.framePosition)
                    let frames = min(chunk, remaining)
                    guard let buf = AVAudioPCMBuffer(pcmFormat: targetFormat, frameCapacity: frames) else { break }
                    try inFile.read(into: buf, frameCount: frames)
                    if buf.frameLength == 0 { break }
                    let ts = Double(inFile.framePosition - Int64(frames)) / sampleRate

                    if let ch = buf.floatChannelData?.pointee {
                        var ms: Float = 0
                        vDSP_measqv(ch, 1, &ms, vDSP_Length(buf.frameLength))
                        let db: Float = ms <= 0 ? -160 : 10 * log10f(ms)
                        if db > threshDB {
                            if foundStart == nil { foundStart = ts }
                            lastNonSilent = ts + Double(buf.frameLength) / sampleRate
                        }
                    }
                }
                if let fs = foundStart {
                    start = fs
                    end = max(lastNonSilent, fs + 0.1)
                } else {
                    start = 0
                    end = duration
                }
            }

            start = max(0, start - prePad)
            end = min(duration, end + postPad)
            guard end > start else { return inputURL }

            let startFrame = AVAudioFramePosition(start * sampleRate)
            let endFrame = AVAudioFramePosition(end * sampleRate)
            let framesToRead = endFrame - startFrame
            guard framesToRead > 0 else { return inputURL }

            let outURL = inputURL.deletingPathExtension().appendingPathExtension("trim.caf")
            let outFile = try AVAudioFile(forWriting: outURL, settings: inFile.fileFormat.settings)

            inFile.framePosition = startFrame
            let chunkSize: AVAudioFrameCount = 8192
            while inFile.framePosition < endFrame {
                let remaining = AVAudioFrameCount(endFrame - inFile.framePosition)
                let frames = min(chunkSize, remaining)
                guard let buffer = AVAudioPCMBuffer(pcmFormat: inFile.processingFormat, frameCapacity: frames) else { break }
                try inFile.read(into: buffer, frameCount: frames)
                if buffer.frameLength == 0 { break }
                buffer.frameLength = frames
                try outFile.write(from: buffer)
            }
            return outURL
        } catch {
            return inputURL
        }
    }
}