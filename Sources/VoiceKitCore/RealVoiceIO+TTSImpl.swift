//
//  RealVoiceIO+TTSImpl.swift
//  VoiceKit
//
//  AVSpeechSynthesizer setup and delegate method implementations.
//  Delegate methods are nonisolated entry points and immediately hop to @MainActor.
//  We only pass primitive/Sendable data (ObjectIdentifier) across the hop.
//
//  Generated by GPT-5 (OpenAI) — collaborator: rdoggett
//  date: 09-18-2025
//

import Foundation
@preconcurrency import AVFoundation
import CoreGraphics

// MARK: - Synth management and public speak (main-actor)

@MainActor
extension RealVoiceIO {

    internal func ensureSynth() {
        if synthesizer == nil {
            let synth = AVSpeechSynthesizer()
            synth.delegate = self
            synthesizer = synth
        }
    }

    public func speak(_ text: String) async {
        await speak(text, using: defaultProfile?.id)
    }

    /// Speak and return measured wall-clock duration from didStart to didFinish for this utterance.
    /// In CI mode, we avoid AVSpeech and return a tiny synthetic duration.
    public func speakAndMeasure(_ text: String, using voiceID: String?) async -> TimeInterval {
        // CI fast-path: avoid AVSpeech on headless runners.
        if IsCI.running {
            await speak(text, using: voiceID)
            return 0.0
        }

        ensureSynth()
        guard let synthesizer else { return 0.0 }
        let utterance = AVSpeechUtterance(string: text)
        applyProfile(to: utterance, voiceID: voiceID ?? defaultProfile?.id)

        let key = ObjectIdentifier(utterance)
        return await withCheckedContinuation { (cont: CheckedContinuation<TimeInterval, Never>) in
            // Store continuation; didFinish will compute and resume
            measureContinuations[key] = cont
            synthesizer.speak(utterance)
        }
    }

    public func speak(_ text: String, using voiceID: String?) async {
        // CI fast-path: avoid AVSpeech on headless runners where delegate callbacks can stall.
        if IsCI.running {
            log(.info, "speak(ci-fast-path, voiceID:\(voiceID ?? "nil"))")
            onTTSSpeakingChanged?(true)
            ttsStartPulse()
            await Task.yield()
            onTTSSpeakingChanged?(false)
            ttsStopPulse()
            return
        }

        ensureSynth()
        log(.info, "speak(text:\(text.prefix(48))\(text.count > 48 ? "…" : ""), voiceID:\(voiceID ?? "nil"))")
        guard let synthesizer else { return }
        let utterance = AVSpeechUtterance(string: text)
        applyProfile(to: utterance, voiceID: voiceID ?? defaultProfile?.id)

        let key = ObjectIdentifier(utterance)
        do {
            try await withCheckedThrowingContinuation { (cont: CheckedContinuation<Void, Error>) in
                speakContinuations[key] = cont
                synthesizer.speak(utterance)
            }
        } catch {
            ttsStopPulse()
            log(.error, "speak(error): \(error.localizedDescription)")
        }
    }

    internal func applyProfile(to utterance: AVSpeechUtterance, voiceID: String?) {
        if let voiceID, let voice = AVSpeechSynthesisVoice(identifier: voiceID) {
            utterance.voice = voice
        }

        let control = master
        utterance.rate = Float((defaultProfile?.rate ?? 0.5).clamped(to: 0...1))
        utterance.pitchMultiplier = (defaultProfile?.pitch ?? 1.0) + .random(in: -control.pitchVariation...control.pitchVariation)
        utterance.volume = defaultProfile?.volume ?? 1.0

        if let id = voiceID, let profile = profilesByID[id] {
            utterance.rate = Float(profile.rate.clamped(to: 0...1))
            utterance.pitchMultiplier = profile.pitch + .random(in: -control.pitchVariation...control.pitchVariation)
            utterance.volume = profile.volume
        }

        utterance.rate += .random(in: -control.rateVariation...control.rateVariation)
    }

    internal func ttsStartPulse() {}
    internal func ttsStopPulse() {}
}

// MARK: - AVSpeechSynthesizerDelegate (nonisolated entry points; hop to main)

extension RealVoiceIO {

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didStart utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            self.log(.info, "tts didStart")
            self.onTTSSpeakingChanged?(true)
            self.ttsStartPulse()
            // Record start time for this utterance (used by speakAndMeasure)
            let now = ProcessInfo.processInfo.systemUptime
            self.ttsStartTimes[key] = now
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didFinish utterance: AVSpeechUtterance) {
        // Capture ObjectIdentifier in nonisolated context; don't send utterance across
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            if let cont = self.speakContinuations.removeValue(forKey: key) {
                cont.resume()
            }
            // If measuring, compute duration and resume continuation
            if let start = self.ttsStartTimes.removeValue(forKey: key),
               let mCont = self.measureContinuations.removeValue(forKey: key) {
                let now = ProcessInfo.processInfo.systemUptime
                let duration = max(0, now - start)
                mCont.resume(returning: duration)
            } else if let mCont = self.measureContinuations.removeValue(forKey: key) {
                // Fallback: no start captured; return 0
                mCont.resume(returning: 0.0)
            }
            self.log(.info, "tts didFinish")
            self.onTTSSpeakingChanged?(false)
            self.ttsStopPulse()
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didCancel utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            if let cont = self.speakContinuations.removeValue(forKey: key) {
                cont.resume()
            }
            // Cancel measurement if any; resume with 0
            if let _ = self.ttsStartTimes.removeValue(forKey: key),
               let mCont = self.measureContinuations.removeValue(forKey: key) {
                mCont.resume(returning: 0.0)
            } else if let mCont = self.measureContinuations.removeValue(forKey: key) {
                mCont.resume(returning: 0.0)
            } else {
                // no-op
            }
            self.log(.warn, "tts didCancel")
            self.onTTSSpeakingChanged?(false)
            self.ttsStopPulse()
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              willSpeakRangeOfSpeechString characterRange: NSRange,
                                              utterance: AVSpeechUtterance) {
        Task { @MainActor in
            self.ttsPhase += 0.2
            let glow = max(0, sin(self.ttsPhase))
            self.ttsGlow = CGFloat(glow)
            self.onTTSPulse?(self.ttsGlow)
        }
    }
}

private extension Comparable {
    func clamped(to range: ClosedRange<Self>) -> Self {
        min(max(self, range.lowerBound), range.upperBound)
    }
}
