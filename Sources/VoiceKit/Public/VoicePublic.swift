//
//  VoicePublic.swift
//  VoiceKit
//
//  Generated by GPT-5 (OpenAI)
//  collaborator: rdoggett
//  date: 09-16-2025
//

import Foundation
import CoreGraphics

// Tuning is the canonical control model (rateVariation, pitchVariation, volume).

// MARK: - Public results and errors

public struct VoiceResult: Sendable {
    public let transcript: String
    public let recordingURL: URL?

    public init(transcript: String, recordingURL: URL?) {
        self.transcript = transcript
        self.recordingURL = recordingURL
    }
}

public struct SimpleError: LocalizedError, Sendable {
    public var message: String

    public init(_ message: String) { self.message = message }

    public var errorDescription: String? { message }
}

// MARK: - VoiceIO API (main-actor)

@MainActor
public protocol VoiceIO: AnyObject {
    var onListeningChanged: ((Bool) -> Void)? { get set }
    var onTranscriptChanged: ((String) -> Void)? { get set }
    var onLevelChanged: ((CGFloat) -> Void)? { get set }
    var onTTSSpeakingChanged: ((Bool) -> Void)? { get set }
    var onTTSPulse: ((CGFloat) -> Void)? { get set }
    var onStatusMessageChanged: ((String?) -> Void)? { get set }

    func ensurePermissions() async throws
    func configureSessionIfNeeded() async throws

    func speak(_ text: String) async
    func listen(timeout: TimeInterval, inactivity: TimeInterval, record: Bool) async throws -> VoiceResult

    func prepareClip(url: URL, gainDB: Float) async throws
    func startPreparedClip() async throws
    func playClip(url: URL, gainDB: Float) async throws

    func stopAll()
    func hardReset()
}

@MainActor
public extension VoiceIO {
    func prepareClip(url: URL) async throws { try await prepareClip(url: url, gainDB: 0) }
    func playClip(url: URL) async throws { try await playClip(url: url, gainDB: 0) }
    func queueSFX(url: URL, gainDB: Float = 0) async throws { try await prepareClip(url: url, gainDB: gainDB) }

    func listen(timeout: TimeInterval,
                inactivity: TimeInterval,
                record: Bool,
                context: RecognitionContext = .init()) async throws -> VoiceResult {
        if let real = self as? RealVoiceIO {
            real.setRecognitionContext(context)
        }
        return try await listen(timeout: timeout, inactivity: inactivity, record: record)
    }
}

// MARK: - TTS models and configuration

public struct TTSVoiceInfo: Identifiable, Hashable, Codable, Sendable {
    public let id: String
    public let name: String
    public let language: String

    public init(id: String, name: String, language: String) {
        self.id = id; self.name = name; self.language = language
    }
}

public struct TTSVoiceProfile: Sendable, Equatable, Codable {
    public let id: String
    public var rate: Double
    public var pitch: Float
    public var volume: Float

    public init(id: String, rate: Double = 0.5, pitch: Float = 1.0, volume: Float = 1.0) {
        self.id = id
        self.rate = rate
        self.pitch = pitch
        self.volume = volume
    }
}

public struct Tuning: Sendable, Equatable, Codable {
    public var rateVariation: Float
    public var pitchVariation: Float
    public var volume: Float

    public init(rateVariation: Float = 0, pitchVariation: Float = 0, volume: Float = 1.0) {
        self.rateVariation = rateVariation
        self.pitchVariation = pitchVariation
        self.volume = volume
    }
}

/// Annotated @MainActor to match RealVoiceIOâ€™s isolation and allow calls through existential.
@MainActor
public protocol TTSConfigurable: AnyObject {
    func setVoiceProfile(_ profile: TTSVoiceProfile)
    func getVoiceProfile(id: String) -> TTSVoiceProfile?
    func setDefaultVoiceProfile(_ profile: TTSVoiceProfile)
    func getDefaultVoiceProfile() -> TTSVoiceProfile?
    func setTuning(_ tuning: Tuning)
    func getTuning() -> Tuning

    /// Speak text using an optional voice profile id (nil uses default).
    func speak(_ text: String, using voiceID: String?) async
}

// MARK: - Recognition context

public struct RecognitionContext: Sendable {
    public enum Expectation: Sendable {
        case freeform
        case name(allowed: [String])
        case number
    }

    public var expectation: Expectation

    public init(expectation: Expectation = .freeform) { self.expectation = expectation }
}

public extension RecognitionContext {
    static var numericContextualStrings: [String] {
        let digits = (0...20).map { String($0) } + ["30", "40", "50", "60", "70", "80", "90", "100"]
        let words = ["zero", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine",
                     "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen",
                     "sixteen", "seventeen", "eighteen", "nineteen", "twenty",
                     "thirty", "forty", "fifty", "sixty", "seventy", "eighty", "ninety", "hundred"]
        return digits + words
    }
}

// MARK: - Operation gate

public actor VoiceOpGate {
    private var busy = false

    public init() {}

    public func acquire() async {
        while busy { try? await Task.sleep(nanoseconds: 200_000) }
        busy = true
    }
    public func release() async { busy = false }
    public func forceClear() async { busy = false }
}
