//
//  RealVoiceIO+TTSImpl.swift
//  VoiceKit
//
//  AVSpeechSynthesizer setup and delegate method implementations.
//  Delegate methods are nonisolated entry points and immediately hop to @MainActor.
//  We only pass primitive/Sendable data (ObjectIdentifier) across the hop.
//
//  Generated by GPT-5 (OpenAI) — collaborator: rdoggett
//  date: 09-18-2025
//

import Foundation
@preconcurrency import AVFoundation
import CoreGraphics

// MARK: - Synth management and public speak (main-actor)

@MainActor
extension RealVoiceIO {

    internal func ensureSynth() {
        if synthesizer == nil {
            let synth = AVSpeechSynthesizer()
            synth.delegate = self
            synthesizer = synth
        }
    }

    public func speak(_ text: String) async {
        await speak(text, using: defaultProfile?.id)
    }

    /// Speak and return measured wall-clock duration from didStart to didFinish for this utterance.
    /// In CI mode, we avoid AVSpeech and return a tiny synthetic duration.
    public func speakAndMeasure(_ text: String, using voiceID: String?) async -> TimeInterval {
        // CI fast-path: avoid AVSpeech on headless runners.
        if IsCI.running {
            await speak(text, using: voiceID)
            return 0.0
        }

        ensureSynth()
        guard let synthesizer else { return 0.0 }
        let utterance = AVSpeechUtterance(string: text)
        applyProfile(to: utterance, voiceID: voiceID ?? defaultProfile?.id)

        let key = ObjectIdentifier(utterance)
        return await withCheckedContinuation { (cont: CheckedContinuation<TimeInterval, Never>) in
            // Store continuation; didFinish will compute and resume
            measureContinuations[key] = cont
            synthesizer.speak(utterance)
        }
    }

    public func speak(_ text: String, using voiceID: String?) async {
        // CI fast-path: avoid AVSpeech on headless runners where delegate callbacks can stall.
        if IsCI.running {
            log(.info, "speak(ci-fast-path, voiceID:\(voiceID ?? "nil"))")
            onTTSSpeakingChanged?(true)
            ttsStartPulse()
            await Task.yield()
            onTTSSpeakingChanged?(false)
            ttsStopPulse()
            return
        }

        ensureSynth()
        log(.info, "speak(text:\(text.prefix(48))\(text.count > 48 ? "…" : ""), voiceID:\(voiceID ?? "nil"))")
        guard let synthesizer else { return }
        let utterance = AVSpeechUtterance(string: text)
        applyProfile(to: utterance, voiceID: voiceID ?? defaultProfile?.id)

        let key = ObjectIdentifier(utterance)
        do {
            try await withCheckedThrowingContinuation { (cont: CheckedContinuation<Void, Error>) in
                speakContinuations[key] = cont
                synthesizer.speak(utterance)
            }
        } catch {
            ttsStopPulse()
            log(.error, "speak(error): \(error.localizedDescription)")
        }
    }

    internal func applyProfile(to utterance: AVSpeechUtterance, voiceID: String?) {
        if let voiceID, let voice = AVSpeechSynthesisVoice(identifier: voiceID) {
            utterance.voice = voice
        }

        let control = tuning
        // Map normalized 0…1 rate into AVSpeechUtterance native range for audibly stronger effect.
        let sysMin = AVSpeechUtteranceMinimumSpeechRate
        let sysMax = AVSpeechUtteranceMaximumSpeechRate
        let sysSpan = sysMax - sysMin
        func mapRate(_ normalized: Double) -> Float {
            let clamped = Float(normalized.clamped(to: 0.0...1.0))
            return (sysMin + clamped * sysSpan).clamped(to: sysMin...sysMax)
        }

        // Defaults
        let baseNormRate = (defaultProfile?.rate ?? 0.5).clamped(to: 0.0...1.0)
        var mappedRate = mapRate(baseNormRate)
        var usedNormRate = baseNormRate
        var source = "default"
        // Apply per-utterance random rate variation in system units (preserving semantics of tuning.rateVariation as normalized fraction).
        let rateDelta = Float.random(in: -control.rateVariation...control.rateVariation) * sysSpan
        utterance.rate = (mappedRate + rateDelta).clamped(to: sysMin...sysMax)

        // Pitch and volume with gentle randomization and clamping to valid ranges.
        let basePitch = (defaultProfile?.pitch ?? 1.0)
        utterance.pitchMultiplier = (basePitch + .random(in: -control.pitchVariation...control.pitchVariation)).clamped(to: 0.5...2.0)
        utterance.volume = (defaultProfile?.volume ?? 1.0).clamped(to: 0.0...1.0)

        if let id = voiceID, let profile = profilesByID[id] {
            let norm = profile.rate.clamped(to: 0.0...1.0)
            mappedRate = mapRate(norm)
            let delta = Float.random(in: -control.rateVariation...control.rateVariation) * sysSpan
            utterance.rate = (mappedRate + delta).clamped(to: sysMin...sysMax)
            usedNormRate = norm
            source = "profile"

            let pitchValue = profile.pitch + .random(in: -control.pitchVariation...control.pitchVariation)
            utterance.pitchMultiplier = pitchValue.clamped(to: 0.5...2.0)
            utterance.volume = profile.volume.clamped(to: 0.0...1.0)
        }
        // Note: rate variation already applied above relative to system span.

        // Unconditional trace for debugging (visible in Xcode Previews too).
        let vname = utterance.voice?.name ?? "system-default"
        let trace = "applyProfile[\(source)] id=\(voiceID ?? "nil") name=\(vname) norm=\(String(format: "%.3f", usedNormRate)) avRate=\(String(format: "%.3f", utterance.rate)) pitch=\(String(format: "%.3f", utterance.pitchMultiplier)) vol=\(String(format: "%.2f", utterance.volume))"
        log(.info, trace)
        // Also print so Xcode Previews shows it even if the logger is muted
        print("[VoiceKit]", trace)
    }

    internal func ttsStartPulse() {}
    internal func ttsStopPulse() {}
}

// MARK: - AVSpeechSynthesizerDelegate (nonisolated entry points; hop to main)

extension RealVoiceIO {

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didStart utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            self.log(.info, "tts didStart")
            self.onTTSSpeakingChanged?(true)
            self.ttsStartPulse()
            // Record start time for this utterance (used by speakAndMeasure)
            let now = ProcessInfo.processInfo.systemUptime
            self.ttsStartTimes[key] = now
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didFinish utterance: AVSpeechUtterance) {
        // Capture ObjectIdentifier in nonisolated context; don't send utterance across
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            if let cont = self.speakContinuations.removeValue(forKey: key) {
                cont.resume()
            }
            // If measuring, compute duration and resume continuation
            if let start = self.ttsStartTimes.removeValue(forKey: key),
               let mCont = self.measureContinuations.removeValue(forKey: key) {
                let now = ProcessInfo.processInfo.systemUptime
                let duration = max(0, now - start)
                mCont.resume(returning: duration)
            } else if let mCont = self.measureContinuations.removeValue(forKey: key) {
                // Fallback: no start captured; return 0
                mCont.resume(returning: 0.0)
            }
            self.log(.info, "tts didFinish")
            self.onTTSSpeakingChanged?(false)
            self.ttsStopPulse()
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              didCancel utterance: AVSpeechUtterance) {
        let key = ObjectIdentifier(utterance)
        Task { @MainActor in
            if let cont = self.speakContinuations.removeValue(forKey: key) {
                cont.resume()
            }
            // Cancel measurement if any; resume with 0
            if self.ttsStartTimes.removeValue(forKey: key) != nil,
               let mCont = self.measureContinuations.removeValue(forKey: key) {
                mCont.resume(returning: 0.0)
            } else if let mCont = self.measureContinuations.removeValue(forKey: key) {
                mCont.resume(returning: 0.0)
            } else {
                // no-op
            }
            self.log(.warn, "tts didCancel")
            self.onTTSSpeakingChanged?(false)
            self.ttsStopPulse()
        }
    }

    nonisolated public func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer,
                                              willSpeakRangeOfSpeechString characterRange: NSRange,
                                              utterance: AVSpeechUtterance) {
        Task { @MainActor in
            self.ttsPhase += 0.2
            let glow = max(0, sin(self.ttsPhase))
            self.ttsGlow = CGFloat(glow)
            self.onTTSPulse?(self.ttsGlow)
        }
    }
}
